{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davmo\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.corpora.csvcorpus import CsvCorpus\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_details(qw, cw, gw, res, model_name):\n",
    "    with open(model_name, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['question-word', 'correct-word', 'guess-word', 'result']\n",
    "        detail_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        info = os.stat(model_name)\n",
    "        if info.st_size == 0:\n",
    "            detail_writer.writeheader()\n",
    "\n",
    "        detail_writer.writerow({'question-word': qw, 'correct-word': cw, 'guess-word': gw, 'result' : res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_processing(model_name):\n",
    "    for index, question in synonyms.iterrows():\n",
    "        try:\n",
    "            similarities = [google_news.similarity(question[0], word) for word in question if word is not question[0] and word is not question[1]]\n",
    "            max_value = max(similarities)\n",
    "            max_index = similarities.index(max_value)\n",
    "            question_word, answer_word, guess_word, = question[0], question[1], question[max_index+2]\n",
    "            zipped_list = zip(question[2:], similarities)\n",
    "            word_score_dict = dict(zipped_list)\n",
    "            \n",
    "            if question[max_index+2] == question[1]:\n",
    "                model_details(question_word, answer_word, guess_word, 'True')\n",
    "            else:\n",
    "                model_details(question_word, answer_word, guess_word, 'False')\n",
    "                \n",
    "        except KeyError:\n",
    "            question_word, answer_word, guess_word, = question[0], question[1], question[max_index+2]\n",
    "            model_details(question_word, answer_word, guess_word, 'Guess')\n",
    "            print('----- ' + str(index) + ' = Not Available------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_info = api.info()\n",
    "# print(available_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models from different corpora, but same embedding size (Task 2.3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikinews_corpus_300 = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "conceptnet_corpus_300 = api.load(\"conceptnet-numberbatch-17-06-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models from same corpus, but different embedding sizes (Task 2.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glovetwitter_corpus_25 = api.load(\"glove-twitter-25\")\n",
    "glovetwitter_corpus_50 = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating statistics and appending to analysis.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Brandon, this is where you would practically copy and paste what you did for Task 1, but for every model above. I'm leaving placeholders for the time being.\n",
    "file = open(\"analysis.csv\",\"a\", newline=\"\", encoding = \"utf-8\")\n",
    "\n",
    "wikinews_model_300_name = \"fasttext-wiki-news-subwords-300\"\n",
    "wikinews_model_300_vocabulary_size = 25000\n",
    "wikinews_model_300_vocabulary_correct = 130\n",
    "wikinews_model_300_vocabulary_guess = 24870\n",
    "wikinews_model_300_accuracy = wikinews_model_300_vocabulary_correct / wikinews_model_300_vocabulary_guess\n",
    "file.write(wikinews_model_300_name +\",\"+\"{}\".format(wikinews_model_300_vocabulary_size)+\",\"+\"{}\".format(wikinews_model_300_vocabulary_correct)+\"{}\".format(wikinews_model_300_vocabulary_guess)+\",\"+\"{}\".format(wikinews_model_300_accuracy))\n",
    "\n",
    "conceptnet_model_300_name = \"conceptnet-numberbatch-17-06-300\"\n",
    "conceptnet_model_300_vocabulary_size = 15000\n",
    "conceptnet_model_300_vocabulary_correct = 30\n",
    "conceptnet_model_300_vocabulary_guess = 14970\n",
    "conceptnet_model_300_accuracy = conceptnet_model_300_vocabulary_correct / conceptnet_model_300_vocabulary_guess\n",
    "file.write(conceptnet_model_300_name +\",\"+\"{}\".format(conceptnet_model_300_vocabulary_size)+\",\"+\"{}\".format(conceptnet_model_300_vocabulary_correct)+\"{}\".format(conceptnet_model_300_vocabulary_guess)+\",\"+\"{}\".format(conceptnet_model_300_accuracy))\n",
    "\n",
    "glovetwitter_model_25_name = \"glove-twitter-25\"\n",
    "glovetwitter_model_25_vocabulary_size = 5000\n",
    "glovetwitter_model_25_vocabulary_correct = 10\n",
    "glovetwitter_model_25_vocabulary_guess = 4990\n",
    "glovetwitter_model_25_accuracy = glovetwitter_model_25_vocabulary_correct / glovetwitter_model_25_vocabulary_guess\n",
    "file.write(glovetwitter_model_25_name +\",\"+\"{}\".format(glovetwitter_model_25_vocabulary_size)+\",\"+\"{}\".format(glovetwitter_model_25_vocabulary_correct)+\"{}\".format(glovetwitter_model_25_vocabulary_guess)+\",\"+\"{}\".format(glovetwitter_model_25_accuracy))\n",
    "\n",
    "glovetwitter_model_50_name = \"glove-twitter-50\"\n",
    "glovetwitter_model_50_vocabulary_size = 5000\n",
    "glovetwitter_model_50_vocabulary_correct = 10\n",
    "glovetwitter_model_50_vocabulary_guess = 4990\n",
    "glovetwitter_model_50_accuracy = glovetwitter_model_25_vocabulary_correct / glovetwitter_model_25_vocabulary_guess\n",
    "file.write(glovetwitter_model_50_name +\",\"+\"{}\".format(glovetwitter_model_50_vocabulary_size)+\",\"+\"{}\".format(glovetwitter_model_50_vocabulary_correct)+\"{}\".format(glovetwitter_model_50_vocabulary_guess)+\",\"+\"{}\".format(glovetwitter_model_50_accuracy))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing graphs for every statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"wikinews_vocabulary_size\", \"wikinews_vocabulary_correct\", \"wikinews_vocabulary_guess\", \"wikinews_accuracy\"],[wikinews_model_300_vocabulary_size, wikinews_model_300_vocabulary_correct, wikinews_model_300_vocabulary_guess, wikinews_model_300_accuracy])\n",
    "plt.savefig(\"Wikinews_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"conceptnet_vocabulary_size\", \"conceptnet_vocabulary_correct\", \"conceptnet_vocabulary_guess\", \"conceptnet_accuracy\"],[conceptnet_model_300_vocabulary_size, conceptnet_model_300_vocabulary_correct, conceptnet_model_300_vocabulary_guess, conceptnet_model_300_accuracy])\n",
    "plt.savefig(\"Conceptnet_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"glovetwitter_25_vocabulary_size\", \"glovetwitter_25_vocabulary_correct\", \"glovetwitter_25_vocabulary_guess\", \"glovetwitter_25_accuracy\"],[glovetwitter_model_25_vocabulary_size, glovetwitter_model_25_vocabulary_correct, glovetwitter_model_25_vocabulary_guess, glovetwitter_model_25_accuracy])\n",
    "plt.savefig(\"Glovetwitter_25_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"glovetwitter_50_vocabulary_size\", \"glovetwitter_50_vocabulary_correct\", \"glovetwitter_50_vocabulary_guess\", \"glovetwitter_50_accuracy\"],[glovetwitter_model_50_vocabulary_size, glovetwitter_model_50_vocabulary_correct, glovetwitter_model_50_vocabulary_guess, glovetwitter_model_50_accuracy])\n",
    "plt.savefig(\"Glovetwitter_50_statistics.pdf\")\n",
    "# Mostly done here, waiting on human gold standard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d6f8a830624f0388fba043bda1ab3394ab2d7a44fb0c72262b70fc45ad485ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
