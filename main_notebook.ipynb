{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.corpora.csvcorpus import CsvCorpus\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = pd.read_csv(\"synonyms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_details(qw, cw, gw, res, model_name):\n",
    "    with open(model_name, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['question-word', 'correct-word', 'guess-word', 'result']\n",
    "        detail_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        info = os.stat(model_name)\n",
    "        if info.st_size == 0:\n",
    "            detail_writer.writeheader()\n",
    "\n",
    "        detail_writer.writerow({'question-word': qw, 'correct-word': cw, 'guess-word': gw, 'result' : res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be removed\n",
    "def analysis(mn, vs, c, v, a):\n",
    "    with open('analysis.csv', 'a', newline='') as csvfile:\n",
    "        fieldnames = ['Model Name', 'Vocabulary Size', 'C', 'V', 'Accuracy']\n",
    "        analysis_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        info = os.stat('analysis.csv')\n",
    "        if info.st_size == 0:\n",
    "            analysis_writer.writeheader()\n",
    "\n",
    "        analysis_writer.writerow({'Model Name': mn, 'Vocabulary Size': vs, 'C': c, 'V' : v, 'Accuracy': a})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates pre-trained model's ability to correctly guess the given corpus (in this case synonyms.csv) and returns a pandas dataframe\n",
    "# containing the question word, the correct answer, the model's guess and whether the guess is correct or wrong\n",
    "\n",
    "def model_evaluation(model, corpus):\n",
    "\n",
    "    # Initializes columns for dataframe\n",
    "    question_col, answer_col, guess_col, result_col = [], [], [], []\n",
    "\n",
    "    # vecotrizes the similarity function so it can be applied across the numpy arrays comparing it with the four choices of words\n",
    "    check_similarity = np.vectorize(model.similarity)\n",
    "\n",
    "    # Iterates through each row of the corpus\n",
    "    for index, question in corpus.iterrows():\n",
    "\n",
    "        # extracts the question word, answer word, and choice words\n",
    "        question_word, answer_word, choice_words = question[0], question[1], np.array(question)[2:]\n",
    "\n",
    "        try:\n",
    "            # checks if no choice words are present, if no choice words available - goes to except\n",
    "            if not pd.isnull(choice_words.all()) == 0:\n",
    "                raise KeyError\n",
    "           \n",
    "            # gets an array of the cosine similarities between the question word and the choice words\n",
    "            # and selects word with the highest value\n",
    "            similarities = check_similarity(question_word, choice_words)\n",
    "            guess_word = choice_words[similarities.argmax()]\n",
    "            \n",
    "            # adds question word, answer word, and guess word to their respective column\n",
    "            question_col.append(question_word)\n",
    "            answer_col.append(answer_word)\n",
    "            guess_col.append(guess_word)\n",
    "\n",
    "            # adds correct/wrong to result column\n",
    "            result_col.append('Correct') if guess_word == answer_word else result_col.append('Wrong')\n",
    "            \n",
    "        except KeyError:\n",
    "            # adds question word and answer word to their respective column and adds 'N/A' to guess column as well as 'Guess' to result column\n",
    "            # due to the fact that either the question word and/or all the choice words are not present in the model\n",
    "            question_col.append(question_word)\n",
    "            answer_col.append(answer_word)\n",
    "            guess_col.append('N/A')\n",
    "            result_col.append('Guess')\n",
    "    \n",
    "    return pd.DataFrame({'question word' : question_col, 'answer word': answer_col, 'guess word': guess_col, 'result': result_col})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets statistics of correct and wrong guesses from evaluated model\n",
    "def get_stats(model_data):\n",
    "    # extracts the result column from the model_data and counts the amount of correct and wrong guesses\n",
    "    results = pd.value_counts(model_data['result'])  \n",
    "    correct_count = results['Correct']\n",
    "    wrong_count = results['Wrong']\n",
    "    guess_count = results['Guess']\n",
    "    v_statistic= correct_count+wrong_count+guess_count\n",
    "    accuracy = correct_count / v_statistic\n",
    "    return correct_count, v_statistic, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_info = api.info()\n",
    "# print(available_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models from different corpora, but same embedding size (Task 2.3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikinews_corpus_300 = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "conceptnet_corpus_300 = api.load(\"conceptnet-numberbatch-17-06-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 models from same corpus, but different embedding sizes (Task 2.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glovetwitter_corpus_25 = api.load(\"glove-twitter-25\")\n",
    "glovetwitter_corpus_50 = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating statistics and appending to analysis.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Correct'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Correct'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-28096a63358c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mconcepnet_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconceptnet_model_300_name_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mconceptnet_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcepnet_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mconceptnet_model_300_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_v_statistic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconceptnet_dataframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mconceptnet_model_300_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconceptnet_model_300_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_vocabulary_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_v_statistic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconceptnet_model_300_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmy_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconceptnet_model_300_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-40c2c1dfe953>\u001b[0m in \u001b[0;36mget_stats\u001b[1;34m(model_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# extracts the result column from the model_data and counts the amount of correct and wrong guesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcorrect_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Correct'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mwrong_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wrong'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mguess_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Guess'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Correct'"
     ]
    }
   ],
   "source": [
    "analysis_csv= open(\"analysis.csv\",\"a\")\n",
    "my_writer = writer(analysis_csv)\n",
    "wikinews_model_300_name = \"fasttext-wiki-news-subwords-300\"\n",
    "wikinews_model_300_name_doc = wikinews_model_300_name + \"-details.csv\"\n",
    "wikinews_model_300_vocabulary_size = len(wikinews_corpus_300)\n",
    "wikinews_dataframe = model_evaluation(wikinews_corpus_300, synonyms)\n",
    "wikinews_csv = open(wikinews_model_300_name_doc,\"a\")\n",
    "wikinews_dataframe.to_csv(path_or_buf=wikinews_csv, index=False)\n",
    "wikinews_model_300_correct, wikinews_model_300_v_statistic, wikinews_model_300_accuracy = get_stats(wikinews_dataframe)\n",
    "wikinews_model_300_list = [wikinews_model_300_name, wikinews_model_300_vocabulary_size, wikinews_model_300_correct, wikinews_model_300_v_statistic, wikinews_model_300_accuracy]\n",
    "my_writer.writerow(wikinews_model_300_list)\n",
    "\n",
    "conceptnet_model_300_name = \"conceptnet-numberbatch-17-06-300\"\n",
    "conceptnet_model_300_name_doc = conceptnet_model_300_name + \"-details.csv\"\n",
    "conceptnet_model_300_vocabulary_size = len(conceptnet_corpus_300)\n",
    "conceptnet_dataframe = model_evaluation(conceptnet_corpus_300, synonyms)\n",
    "concepnet_csv = open(conceptnet_model_300_name_doc, \"a\")\n",
    "conceptnet_dataframe.to_csv(path_or_buf=concepnet_csv, index=False)\n",
    "conceptnet_model_300_correct, conceptnet_model_300_v_statistic, conceptnet_model_300_accuracy = get_stats(conceptnet_dataframe)\n",
    "conceptnet_model_300_list = [conceptnet_model_300_name, conceptnet_model_300_vocabulary_size, conceptnet_model_300_correct, conceptnet_model_300_v_statistic, conceptnet_model_300_accuracy]\n",
    "my_writer.writerow(conceptnet_model_300_list)\n",
    "\n",
    "glovetwitter_model_25_name = \"glove-twitter-25\"\n",
    "glovetwitter_model_25_name_doc = glovetwitter_model_25_name + \"-details.csv\"\n",
    "glovetwitter_model_25_vocabulary_size = len(glovetwitter_corpus_25)\n",
    "glovetwitter_25_dataframe = model_evaluation(glovetwitter_corpus_25, synonyms)\n",
    "glovetwitter_25_csv = open(glovetwitter_model_25_name_doc,\"a\")\n",
    "glovetwitter_25_dataframe.to_csv(path_or_buf=glovetwitter_25_csv, index=False)\n",
    "glovetwitter_model_25_correct, glovetwitter_model_25_v_statistic, glovetwitter_model_25_accuracy = get_stats(glovetwitter_25_dataframe)\n",
    "glovetwitter_model_25_list = [glovetwitter_model_25_name, glovetwitter_model_25_vocabulary_size, glovetwitter_model_25_correct, glovetwitter_model_25_v_statistic, glovetwitter_model_25_accuracy]\n",
    "my_writer.writerow(glovetwitter_model_25_list)\n",
    "\n",
    "glovetwitter_model_50_name = \"glove-twitter-50\"\n",
    "glovetwitter_model_50_name_doc = glovetwitter_model_50_name + \"-details.csv\"\n",
    "glovetwitter_model_50_vocabulary_size = len(glovetwitter_corpus_50)\n",
    "glovetwitter_50_dataframe = model_evaluation(glovetwitter_corpus_50, synonyms)\n",
    "glovetwitter_50_csv = open(glovetwitter_model_50_name_doc,\"a\")\n",
    "glovetwitter_50_dataframe.to_csv(path_or_buf=glovetwitter_50_csv, index=False)\n",
    "glovetwitter_model_50_correct, glovetwitter_model_50_v_statistic, glovetwitter_model_50_accuracy = get_stats(glovetwitter_50_dataframe)\n",
    "glovetwitter_model_50_list = [glovetwitter_model_50_name, glovetwitter_model_50_vocabulary_size, glovetwitter_model_50_correct, glovetwitter_model_50_v_statistic, glovetwitter_model_50_accuracy]\n",
    "my_writer.writerow(glovetwitter_model_50_list)\n",
    "my_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing graphs for every statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"wikinews_vocabulary_size\", \"wikinews_correct\", \"wikinews_guesses\", \"wikinews_accuracy\"],[wikinews_model_300_vocabulary_size, wikinews_model_300_correct, wikinews_model_300_v_statistic, wikinews_model_300_accuracy])\n",
    "plt.savefig(\"Wikinews_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"conceptnet_vocabulary_size\", \"conceptnet_correct\", \"conceptnet_guesses\", \"conceptnet_accuracy\"],[conceptnet_model_300_vocabulary_size, conceptnet_model_300_correct, conceptnet_model_300_v_statistic, conceptnet_model_300_accuracy])\n",
    "plt.savefig(\"Conceptnet_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"glovetwitter_25_vocabulary_size\", \"glovetwitter_25_correct\", \"glovetwitter_25_guesses\", \"glovetwitter_25_accuracy\"],[glovetwitter_model_25_vocabulary_size, glovetwitter_model_25_correct ,glovetwitter_model_25_v_statistic, glovetwitter_model_25_accuracy])\n",
    "plt.savefig(\"Glovetwitter_25_statistics.pdf\")\n",
    "\n",
    "plt.bar([\"glovetwitter_50_vocabulary_size\", \"glovetwitter_50_correct\", \"glovetwitter_50_guesses\", \"glovetwitter_50_accuracy\"],[glovetwitter_model_50_vocabulary_size, glovetwitter_model_50_correct, glovetwitter_model_50_v_statistic, glovetwitter_model_50_accuracy])\n",
    "plt.savefig(\"Glovetwitter_50_statistics.pdf\")\n",
    "# Mostly done here, waiting on human gold standard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d6f8a830624f0388fba043bda1ab3394ab2d7a44fb0c72262b70fc45ad485ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
